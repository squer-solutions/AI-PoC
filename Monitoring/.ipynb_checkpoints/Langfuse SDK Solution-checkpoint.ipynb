{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solution_intro",
   "metadata": {},
   "source": [
    "# Introducing Langfuse SDK - Solution\n",
    "\n",
    "This notebook demonstrates how to integrate the Langfuse SDK into a Python application to trace and observe language model calls using the low-level SDK. We will use the GPT-2 text generation model from the `transformers` library as an example.\n",
    "\n",
    "This approach provides fine-grained control over tracing individual LLM calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "langfuse_signup",
   "metadata": {},
   "source": [
    "## Sign Up for Langfuse\n",
    "\n",
    "Before you begin, you need to sign up for a free Langfuse account to get your API keys. Follow these steps:\n",
    "\n",
    "1.  Go to the Langfuse website: [https://langfuse.com/](https://langfuse.com/)\n",
    "2.  Click on \"Sign Up\".\n",
    "3.  Follow the instructions to create your account.\n",
    "4.  Once logged in, navigate to your project settings to find your **Public Key** and **Secret Key**. You will also need your **Host** URL (usually `https://cloud.langfuse.com`).\n",
    "5.  Keep these keys handy. It is highly recommended to set these as environment variables (`LANGFUSE_PUBLIC_KEY`, `LANGFUSE_SECRET_KEY`, `LANGFUSE_HOST`) before running this notebook for security. Research how to set environment variables in your operating system or within a Jupyter environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution_installation",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "We need to install the `langfuse` SDK and `openai`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solution_install_libs",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install the required libraries\n",
    "!pip install langfuse openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution_setup",
   "metadata": {},
   "source": [
    "## 2. Langfuse and Model Setup\n",
    "\n",
    "Import the necessary libraries and initialize Langfuse. Langfuse will automatically pick up your API keys and host from environment variables if they are set. We will also load the GPT-2 model using the `transformers` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solution_import_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langfuse import Langfuse\n",
    "from langfuse.openai import openai\n",
    "\n",
    "\n",
    "# Initialize Langfuse. It reads keys from environment variables by default.\n",
    "# Ensure LANGFUSE_PUBLIC_KEY, LANGFUSE_SECRET_KEY, and LANGFUSE_HOST are set.\n",
    "\n",
    "%env LANGFUSE_SECRET_KEY=sk-lf-30d71f39-9615-\"NOT_A_SECRET\"4e6b-a0f7-ec1b8d14acf7\n",
    "%env LANGFUSE_PUBLIC_KEY=pk-lf-e3e8cfc3-e32e-\"NOT_A_SECRET\"4b9b-a02f-53ada416db02\n",
    "%env LANGFUSE_HOST=https://cloud.langfuse.com\n",
    "\n",
    "\n",
    "# init langfuse\n",
    "langfuse = Langfuse()\n",
    "print(\"Langfuse initialized successfully.\")\n",
    "\n",
    "# Set your OpenAI key\n",
    "%env OPENAI_API_KEY=sk-proj-HcISSR8XOPMprVXYvbuDr\"NOT_A_SECRET\"TpoJ1dGEmfHeGJ0BSz_DjovWx9Xo7A0TMC7LFgiz6dVoadO6CjKSZT3BlbkFJrjdD81WmRDcLgs8vHTBPk2PHa7GGskKEm2tOCH54ZLCltsyRoIvuwRE8N3RXbM04hmngjGEqUA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution_tracing",
   "metadata": {},
   "source": [
    "## 3. Tracing with Langfuse \n",
    "\n",
    "We will now trace a single text generation call using the Langfuse SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solution_trace_call",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example traced generation with Langfuse\n",
    "completion = openai.chat.completions.create(\n",
    "  name=\"test-chat\",\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a very accurate calculator. You output only the result of the calculation.\"},\n",
    "      {\"role\": \"user\", \"content\": \"1 + 1 = \"}],\n",
    "  temperature=0,\n",
    "  metadata={\"someMetadataKey\": \"someValue\"},\n",
    ")\n",
    "# flush events\n",
    "langfuse.flush()\n",
    "print(\"Langfuse events flushed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution_view_trace",
   "metadata": {},
   "source": [
    "## 4. View the Trace in Langfuse\n",
    "\n",
    "After running the previous cell (and if Langfuse was initialized successfully), a trace for the GPT-2 generation will be sent to your Langfuse project. Go to your Langfuse project UI ([https://cloud.langfuse.com/](https://cloud.langfuse.com/) or your self-hosted instance) to view the trace details. You should see the input prompt, the generated output, model parameters, metadata, and timing information. https://cloud.langfuse.com/project/cmav0p58a00auad07tw7v86eq/traces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
